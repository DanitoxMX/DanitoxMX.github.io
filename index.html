<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Guillermo Santamaría" />
<meta name="author" content="Daniel Díaz" />


<title>Desarrollo de una herramienta de Machine Learning para el aprovechamiento de información en texto del entrenamiento del personal del sector energético.</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ontología en R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Desarrollo de una herramienta de Machine Learning para el aprovechamiento de información en texto del entrenamiento del personal del sector energético.</h1>
<h4 class="author">Guillermo Santamaría<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></h4>
<h4 class="author">Daniel Díaz<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></h4>
<h4 class="date">Julio, 2019</h4>

</div>


<style type="text/css">


h1.title {
  font-size: 32px;
}
h1 { /* Header 1 */
  font-size: 28px;
}
h2 { /* Header 2 */
  font-size: 22px;
}
h3 { /* Header 3 */
  font-size: 18px;
}

</style>
<hr />
<div id="introduccion" class="section level1">
<h1>Introducción</h1>
</div>
<div id="pipeline" class="section level1">
<h1>Pipeline</h1>
<blockquote>
<p>A continuación se muestra el pipeline utilizado</p>
</blockquote>
<p><img src="img/pipeline.png" /></p>
</div>
<div id="dataset" class="section level1">
<h1>Dataset</h1>
<blockquote>
<p>El conjunto de datos utilizados corresponde a las descripciones textuales de herramientas, equipamientos y materiales requeridos para las maniobras de mantenimiento en la infraestructura de media tensión y microredes.</p>
</blockquote>
</div>
<div id="desarrollo" class="section level1">
<h1>Desarrollo</h1>
<div id="configuracion-inicial" class="section level2">
<h2>Configuración inicial</h2>
<p>Antes de comenzar con el proceso debemos cargar todas las librerias que se utilizaran a lo largo del proyecto. Cargamos el paquete <em>easypackages</em> que nos permite cargar e instalar paquetes con una sola instrucción.</p>
<pre class="r"><code># Si no se tiene instalado
# install.packages(&quot;easypackages&quot;)

library(easypackages)</code></pre>
<p>Colocamos todos los paquetes en un vector y lo pasamos como parámetro a la función de <em>libraries()</em>.</p>
<pre class="r"><code># Todos los paquetes que se necesitan
paquetes &lt;- c(&quot;tm&quot;, &quot;RWeka&quot;, &quot;ggplot2&quot;, &quot;tidyr&quot;, &quot;tibble&quot;, &quot;dplyr&quot;, &quot;corrplot&quot;,
              &quot;httr&quot;, &quot;clValid&quot;, &quot;msos&quot;, &quot;clusterSim&quot;, &quot;tidytext&quot;, &quot;wordcloud&quot;,
              &quot;stats&quot;, &quot;jaccard&quot;, &quot;lsa&quot;, &quot;gtools&quot;, &quot;tidyverse&quot;, &quot;MASS&quot;,&quot;RCurl&quot;,
              &quot;XML&quot;, &quot;magrittr&quot;, &quot;rvest&quot;, &quot;knitr&quot;)

# Instalar los paquetes
# packages(paquetes)

# Cargar los paquetes
libraries(paquetes)</code></pre>
</div>
<div id="extraccion-de-datos" class="section level2">
<h2>Extracción de Datos</h2>
<p>Cargamos los datos con la ruta donde se encuetran.</p>
<pre class="r"><code># Cargamos los datos
load(&quot;data/equipment.Rda&quot;)</code></pre>
<p>Creamos un <em>data frame</em> con el nombre del equipo y su identificador numérico, además, se coloca nombre a las columnas para, posteriormente, transformar el data frame en un corpus.</p>
<blockquote>
<p><strong>“doc_id”</strong> es el identificador de cada documento.</p>
</blockquote>
<blockquote>
<p><strong>“text”</strong> es el contenido del documento</p>
</blockquote>
<pre class="r"><code># Data frame con los datos: id_equip y equip_name
equipo &lt;- as.data.frame(equipment$id_equip)
equipo &lt;- equipo %&gt;%
  mutate(equipment$equip_name) %&gt;%
  setNames(c(&quot;doc_id&quot;,&quot;text&quot;))

head(equipo)</code></pre>
<pre><code>##   doc_id               text
## 1      1     Abrazadera 1AG
## 2      2     Abrazadera 1BS
## 3      3     Abrazadera 2AG
## 4      4     Abrazadera 2BS
## 5      5     Abrazadera 3AG
## 6      6 Abrazadera UC (1U)</code></pre>
</div>
<div id="limpieza-de-datos" class="section level2">
<h2>Limpieza de Datos</h2>
<p>En la limpieza de datos, se consume la mayor cantidad de tiempo empleado en el proyecto. El pre-procesamiento de los documentos comienza con la eliminación de acentos, unidades de medidas, números, puntuación, palabras comunes (stopwords), espacios en blanco y cambiar el texto a minúsculas. Con esto se aumenta la eficiencia y solidez de los resultados por la eliminación de palabras que no favorecen esencialmente al análisis.</p>
<blockquote>
<p>Se escribieron las siguientes funciones para quitar las unidades de medidas y palabras con números y letras.</p>
</blockquote>
<pre class="r"><code># Remover palabras con numeros y letras
remove.alfa_num &lt;- function(x) gsub(&quot;[0-9]+[a-z]+|[a-z]+[0-9]+|[a-z]+[0-9]+[a-z]+|tipo&quot;, &quot; &quot;, x)

# Remover todas las medidas
remove.measure &lt;- function(x) gsub(&quot;\\sx\\s|\\sm\\s|\\scm|\\smm|\\spies|\\spie\\s|\\spie$|\\sno\\s|\\spc|\\sul|\\suc|\\su$|\\sag|\\scu\\s|\\sccf|\\skv|\\srt|\\spv|c\\s|\\m$|adom&quot;,&quot; &quot;,x)</code></pre>
<p>Se comienza a limpiar los datos.</p>
<pre class="r"><code># Quitamos los acentos
equipo$text &lt;- chartr(&#39;áéíóúñ&#39;,&#39;aeioun&#39;,equipo$text)

# Se convierte el dataframe en corpus
docs &lt;- VCorpus(DataframeSource(equipo))

docs &lt;- docs %&gt;%
  # Convertir a minusculas
  tm_map(content_transformer(tolower)) %&gt;%
  # Remover palabras con números y letras
  tm_map(content_transformer(remove.alfa_num)) %&gt;%
  # Remover números
  tm_map(removeNumbers) %&gt;%
  # Remover puntuaciones
  tm_map(removePunctuation) %&gt;%
  # Remover unidades de medidas
  tm_map(content_transformer(remove.measure)) %&gt;%
  # Remover stopwords
  tm_map(removeWords, stopwords(&quot;spanish&quot;)) %&gt;%
  # Remover espacios en blanco
  tm_map(stripWhitespace)</code></pre>
</div>
<div id="bolsa-de-palabras" class="section level2">
<h2>Bolsa de palabras</h2>
<p>Aquí se genera la matriz de términos del documento (Document Term Matrix).</p>
<blockquote>
<p>Primero es necesario crear la función que permita crear los tokens en n-grams, compuestos de una, dos y tres palabras. Se usa la función de <em>NGramTokenizer</em> y pasamos como parámetro el control con las opciones para generar los distintos Tokens.</p>
</blockquote>
<pre class="r"><code>Uni_to_Tri_Tokenize &lt;- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 3))</code></pre>
<p>Se aplica la función de <em>DocumentTermMatrix</em> para generar la matriz de términos de documento incluyendo <em>term frecuency (tf)</em> , como primer parámetro es el corpus y el segundo es el control para generar los Tokens, por lo tanto, se pasa la función recién creada. Al final creamos un objeto de tipo <em>matrix</em> a partir de la objeto tipo <em>DocumentTermMatrix</em></p>
<pre class="r"><code># Creamos la DTM
dtm &lt;- DocumentTermMatrix(docs, control=list(tokenize=Uni_to_Tri_Tokenize))

# Creamos un objeto matrix
matriz.dtm &lt;- as.matrix(dtm)</code></pre>
</div>
<div id="reduccion-de-documentos-sinonimos" class="section level2">
<h2>Reducción de documentos Sinónimos</h2>
<p>Algunos documentos contienen exactamente los mismos tokens con la misma cantidad de apariciones, son documentos con el mismo contenido, por lo tanto pueden ser reducidos utilizando el concepto de “sinónimo”. Para identificar estos documentos se utilizó el índice de Jaccard el cual mide el grado de similitud entre dos conjuntos. Todos los documentos fueron comparados entre si generando una matriz simétrica de los 211 documentos, tomando valores entre 0 y 1, donde 0 indica que dos conjuntos son totalmente diferentes mientras que 1 que los documentos son iguales o, lingüísticamente, “sinónimos”. Para generar el agrupamiento jerárquico, invertimos esta relación mediante la resta 1 menos la matriz, con esto, los documentos totalmente iguales toman un valor de cero.</p>
<blockquote>
<p>La siguiente función permite generar la matriz completa tomando como parámetro la matriz DTM</p>
</blockquote>
<pre class="r"><code>jaccard.matrix &lt;- function(dtm.matrix){
  # Se crea una matriz identidad del tamaño igual a la cantidad de documentos en el corpus
  temp.mat.jacc &lt;- diag(nrow(dtm.matrix))
  for (i in 1:nrow(temp.mat.jacc)) {
    for (j in i:1) {
      if (i != j) {
        # Se aplica la función jaccard() de la libreria &quot;jaccard&quot;
        temp.mat.jacc[i,j] &lt;-  temp.mat.jacc[j,i] &lt;- jaccard(dtm.matrix[i,], dtm.matrix[j,])
      }
    }
  }
  # Se aplican el mismo nombre de las filas a las columnas
  colnames(temp.mat.jacc) &lt;- 1:nrow(dtm.matrix)
  return(temp.mat.jacc)
}</code></pre>
<p>Creamos la matriz con el <em>índice de Jaccard</em> y la visualizamos con una gráfica de correlación.</p>
<pre class="r"><code># Se crea la matriz con el Índice de Jaccard
jaccard.mat &lt;- jaccard.matrix(matriz.dtm)

# Gráfica de correlación
corrplot(jaccard.mat, is.corr = F, method = &quot;circle&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Para tener una mejor visualización de los datos se graficaran los primeros 30 elementos.</p>
<pre class="r"><code># Gráfica de correlación
 corrplot.mixed(jaccard.mat[1:30,1:30], is.corr = F, lower.col = &quot;black&quot;, number.cex = .7, tl.pos = &quot;lt&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Se observa que los documentos del 1 al 7 su valor es 1, por lo tanto, son sinónimos. Los documentos 25 y 26 también cumplen la condición. Estos documentos deben ser comprimidos para tener en la matriz documentos únicos.</p>
<p>Se invierte la relación mediante la resta 1 menos la matriz, se aplica agrupamiento jerárquico con la función <em>hclust</em> y se grafica el dendrograma.</p>
<pre class="r"><code>plot(hclust(as.dist(1-jaccard.mat[1:30,1:30])))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Trabajando con el mismo subconjunto de datos se observa que los documentos del 1 al 7 están agrupados al final del dendrograma con una distancia igual a 0 al igual que los documentos 25 y 26.</p>
<p>Ahora con la función <em>cutree</em> se agrupara la matriz de acuerdo a su distancia, en este caso con una distancia igual a 0.</p>
<pre class="r"><code># Se crea el árbol de agrupamiento jerárquico
hclust.obj &lt;-  hclust(as.dist(1-jaccard.mat))

# Crear grupos con distancia igual a 0
# Guardaremos el grupo al que pertenece cada documento en un vector
vector.words.cluster &lt;- cutree(hclust.obj, h=0)


nuevos.equipos &lt;-  as.matrix(vector.words.cluster)</code></pre>
<p>Extraemos el ID del documento cuando los valores son únicos dentro del vector con el número de cluster al que pertenece cada documento, después, creamos una matriz con dos columnas, la primera será para el ID de los documentos únicos y la segunda el contenido de cada documento.</p>
<pre class="r"><code># Como nombre de columna colocamos el ID de cada documento
rownames(nuevos.equipos) &lt;- equipo$doc_id
# Documentos únicos
new.equip &lt;- rownames(unique(nuevos.equipos))
# Creamos la matriz con los documentos únicos
nuevos.equipos &lt;- matrix(new.equip, nrow=length(new.equip), ncol=2)
# Colocamos el contenido de cada documento
for (i in 1:length(new.equip)) {
  nuevos.equipos[i,2] &lt;- docs[[new.equip[i]]]$content
}
# Convertimos a dataframe
nuevos.equipos &lt;- as.data.frame(nuevos.equipos)
# Cambiamos el nombre a las columnas
colnames(nuevos.equipos) &lt;- c(&quot;doc_id&quot;, &quot;text&quot;)

head(nuevos.equipos)</code></pre>
<pre><code>##   doc_id                                text
## 1      1                         abrazadera 
## 2      8                     cople acoplador
## 3      9                           aislador 
## 4     10 aislador suspension sintetico asus 
## 5     11                  aislador retenida 
## 6     12                   aislador alfiler</code></pre>
<p>Una vez que tenemos los documentos únicos vamos a convertirlos a <em>corpus</em> para crear la nueva DTM</p>
<pre class="r"><code># Convertimos en Corpus
docs.sin.repetir &lt;- VCorpus(DataframeSource(nuevos.equipos))

# Creamos la DTM a partir del corpus nuevo
dtm &lt;- DocumentTermMatrix(docs.sin.repetir, control=list(tokenize=Uni_to_Tri_Tokenize))

# Guardamos como matriz
matriz.dtm &lt;- as.matrix(dtm)

# Aplicamos el índice de Jaccard para la nueva matriz DTM
jaccard.mat.new &lt;- jaccard.matrix(matriz.dtm)

# Cambiamos el nombre de las filas y columnas por el ID del documento.
rownames(jaccard.mat.new) &lt;- rownames(matriz.dtm)
colnames(jaccard.mat.new) &lt;- rownames(matriz.dtm)</code></pre>
<p>Observamos la matriz con agrupamiento jerárquico.</p>
<pre class="r"><code>plot(hclust(as.dist(1-jaccard.mat.new)))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="seleccion-optimo-de-k-clusters" class="section level2">
<h2>Selección óptimo de K clusters</h2>
<p>La siguiente etapa consta en calcular la cantidad óptima de agrupaciones que tendrá nuestro corpus. Primero se crea una matriz con la similitud coseno entre cada documento, esta similitud evalúa el valor coseno del ángulo comprendido entre dos documentos en el espacio siendo 1 cuando ambos documentos son iguales. A partir de esta matriz de distancia se comienzan a evaluar el número de agrupaciones, es importante mencionar que no existe un criterio objetivo para la elección de un numero óptimo de Clusters (agrupaciones), pero podemos usar métodos aproximaciones para medir la calidad del resultado. En nuestro caso, se utiliza el método de Anchura promedio de Silueta, el cual mide cuán la pureza de un cluster en términos de la similitud de los objetos de un grupo en comparación con los elementos del resto.</p>
<p>Creamos una matriz con la similitud de coseno que nos encontrara la relación entre los documentos, para poder utilizar la función es necesario transponer la matriz <em>dtm</em>. Se invierte la relación mediante la resta 1 menos la matriz y se aplica agrupamiento jerárquico con la función <em>hclust</em>.</p>
<pre class="r"><code># Pasamos como parametro la matriz dtm transpuesta
coseno.matriz &lt;- cosine(t(matriz.dtm))

# Aplicamos agrupamiento jerárquico
hclust.obj &lt;-  hclust(as.dist(1-coseno.matriz))</code></pre>
<p>Creamos un vector con los números de clusters para probar y un objeto donde vamos a guardar los promedios para cada cluster</p>
<pre class="r"><code># Vector con el número de clusters
num.pruebas &lt;- 2:100

# Objeto para guardar todos los promedios del método de la silueta.
sil.promedio &lt;- 0</code></pre>
<p>El siguiente ciclo recorrerá todos los clusters y calculara la anchura promedio de Silueta.</p>
<pre class="r"><code>for (i in num.pruebas) {
  # Calculamos la anchura de la silueta
  sil_clu &lt;- silhouette(cutree(hclust.obj, k=i) ,as.dist(1-coseno.matriz), full=T)
  # Calculamos el promedio
  sil.mean.temp &lt;- mean(sil_clu[,3]) 
  # Guardamos el promedio
  sil.promedio[i-1] &lt;-  sil.mean.temp
}</code></pre>
<p>Creamos un <em>data frame</em> con el número de cluster y el promedio de la anchura de Silueta para graficar los resultados.</p>
<pre class="r"><code># Data frame con el número de cluster y promedio de la anchura de Silueta
df.data.sil &lt;- tibble(
  cluster = num.pruebas,
  sil.mean = sil.promedio
)

# Grafica del metodo de la silueta
df.data.sil %&gt;%
  ggplot(aes(x=cluster, y=sil.mean)) +
  geom_point() +
  geom_line() +
  labs(x=&quot;N. Cluster&quot;, y=&quot;Average Silhouette&quot;, title=&quot;Matriz Coseno&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Buscamos el valor que más se acerque a 1, el número de clusters optimo es cuando hay 86 pero la diferencia con el 85 clusters es mínima, por lo tanto, podemos tomar como número optimo 85 de acuerdo a un <a href="https://es.wikipedia.org/wiki/Navaja_de_Ockham#En_estad%C3%ADstica">principio</a> en la estadística el cual debe seleccionarse la combinación más reducida y simple posible de un modelo a estudiar.</p>
<pre class="r"><code>k.optimo &lt;- 85</code></pre>
</div>
<div id="generacion-de-conceptos" class="section level2">
<h2>Generación de Conceptos</h2>
<p>Ahora se tienen 85 clusters en el que cada uno contiene al menos un documento, en algunos casos se obtuvieron agrupaciones con 5 documentos, en este caso, se obtienen las cinco palabras más frecuentes de cada grupo. Estas palabras representan el contenido del grupo.</p>
<p>El primer paso es crear la agrupación con el número de clusters óptimo, después, crearemos una matriz con el contenido de los documentos y el cluster al que perteneces. Una vez que creamos la matriz la convertimos en un <em>data frame</em> y colocamos el nombre a las columnas.</p>
<pre class="r"><code># Aplicamos hclust con el k.optimo
vector.clusters &lt;- cutree(hclust.obj, k=k.optimo)

# Generaremos una matriz con el contenido de los documentos y
# el cluster al que pertenecen.
matriz.doc.cluster &lt;- as.matrix(nuevos.equipos$text)
matriz.doc.cluster &lt;- cbind(matriz.doc.cluster, vector.clusters)

#Lo convertimos en un dataFrame y le cambiamos el nombre a las columnas
df.doc.cluster &lt;- as.data.frame(matriz.doc.cluster)
colnames(df.doc.cluster) &lt;- c(&quot;id.doc&quot;,&quot;cluster&quot;)

head(df.doc.cluster)</code></pre>
<pre><code>##                                 id.doc cluster
## 1                          abrazadera        1
## 8                      cople acoplador       2
## 9                            aislador        3
## 10 aislador suspension sintetico asus        3
## 11                  aislador retenida        3
## 12                   aislador alfiler        4</code></pre>
<p>Se crea una función que será la encargada de tomar el top 5 de cada cluster, pasamos como parámetro los documentos de cada cluster y retornamos las cinco palabras más usadas en un formato listo para realizar las consultas para la NGD, se coloca el signo <strong>+</strong> como separación entre palabras.</p>
<pre class="r"><code>top.5.words &lt;- function(cluster) {
  # Se extraen las primeras 20 palabras de cada cluster
  top20.palabras &lt;- as.data.frame(sort(cluster, T) %&gt;% head(20))
  # Ordenamos las palabras
  top5pala &lt;- sort(table(strsplit(paste(rownames(top20.palabras), collapse = &quot; &quot;), &quot; &quot;)), T) %&gt;% head(5)
  # Retornamos las cinco palabras en formato para NGD.
  top5pala &lt;- paste(rownames(top5pala), collapse = &quot;+&quot;)
  return(top5pala)
}</code></pre>
<p>Creamos un ciclo que recorrerá cada cluster y extraerá sus documentos los cuales pasaran a la función para extraer las 5 palabras más utilizadas y se colocaran en un vector.</p>
<pre class="r"><code># Vector para guardar las top 5 palabras de cada cluster
total.top5 &lt;- 0

for (i in 1:k.optimo) {
  temp &lt;- df.doc.cluster %&gt;%
    filter(cluster==i)
  total.top5[i] &lt;- top.5.words(temp$text)  
}

head(total.top5)</code></pre>
<pre><code>## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot;</code></pre>
</div>
<div id="calculo-de-ngd" class="section level2">
<h2>Calculo de NGD</h2>
<p>La sección se divide en tres, la primera corresponde a la función en R para la Distancia Normalizada de Google, la segunda sección se muestra la configuración de la API Google Custom Search y, al final, se construye la matriz con la NGD.</p>
<div id="funcion-ngd" class="section level3">
<h3>Función NGD</h3>
<p>La distancia normalizada de Google es una medida de similitud semántica derivada de la cantidad de resultados que un motor de búsqueda, como Google o Bing, devuelve para un conjunto dado de palabras. La Distancia Normalizada de Google entre dos términos <em>x</em> e <em>y</em> es:</p>
<p><span class="math display">\[ NGD(x,y) = \frac{max\{log f(x), logf (y)\} - log f(x, y)}
{logN - min\{log f(x), logf (y)\}} \]</span></p>
<p>Donde <em>N</em> es el número total de páginas web buscadas en el motor, <em>f(x)</em> y <em>f(y)</em> es el número de resultados para los términos de búsqueda <em>x</em> e <em>y</em>, <em>f(x, y)</em> es el número de resultado en los que ambos términos aparecen.</p>
<p>La función escrita en R toma tres parámetros, el primero es el número de resultados (también llamados <em>hits</em>) de la búsqueda realizada con el primer término, el segundo parámetro corresponde a los hits del segundo término y el tercer parámetro el número de hits de ambos términos.</p>
<pre class="r"><code>NGD &lt;- function(hits_x, hits_y, hits_x_y){
  NGD_res = (max(log(hits_x), log(hits_y)) - log(hits_x_y)) /
    (log(M) - min( log(hits_x), log(hits_y)) )
  return(NGD_res)
}</code></pre>
</div>
<div id="api-de-google" class="section level3">
<h3>API de Google</h3>
<p>La API permite mostrar los resultados en formato JSON de una consulta de busqueda de manera programable.</p>
<div id="prerrequisitos" class="section level4">
<h4>Prerrequisitos</h4>
<p>Antes de utilizar la API JSON de búsqueda personalizada, primero deberá crear y configurar un motor de búsqueda personalizado. Este será el motor donde se realizaran las consultas. Para crear un nuevo motor de búsqueda debes ir al <a href="https://cse.google.com/cse/all">panel de control del motor de búsqueda.</a></p>
<div id="motor-de-busqueda" class="section level5">
<h5>Motor de Búsqueda</h5>
<ol style="list-style-type: decimal">
<li><p>Inicia sesión con tu cuenta de Google.</p></li>
<li><p>Una vez dentro pulsa el botón de <strong>añadir</strong>.</p></li>
</ol>
<p><img src="img/mtr1.JPG" /></p>
<ol start="3" style="list-style-type: decimal">
<li>En siguiente formulario debemos seleccionar <strong>[1]</strong>las páginas web donde el motor buscará (puedes poner cualquiera, después se eliminara cuando se active la búsqueda en toda la Web), <strong>[2]</strong>el idioma determina el diseño de los botones y otros elementos en el motor de búsqueda, pero no afecta los resultados de búsqueda reales y <strong>[3]</strong>el nombre del motor para su identificación.</li>
</ol>
<p><img src="img/mtr2.png" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Pulsamos el botón de <em>panel de control</em> para entrar a la configuración del motor de búsqueda.</li>
</ol>
<p><img src="img/mtr3.png" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Dentro de la configuración del motor de búsqueda se cambiaran algunas cosas: <strong>[1]</strong> Podemos agregar una descripción para nuestro motor de búsqueda. <strong>[2]</strong> Las palabras clave describen el contenido o el tema de tu motor de búsqueda. Estas palabras clave se utilizan para ajustar los resultados de tu motor de búsqueda. <strong>[3]</strong> El ID del buscador nos servirá para realizar las consultas desde R. <strong>[4]</strong> Seleccionamos el sitio que añadimos al inicio y lo eliminamos. <strong>[5]</strong> Activamos la búsqueda en toda la Web</li>
</ol>
<p><img src="img/mtr4.jpg" /></p>
<blockquote>
<p>Aquí se termina la configuración del motor de búsqueda.</p>
</blockquote>
</div>
<div id="custom-search-api" class="section level5">
<h5>Custom Search API</h5>
<p>Ahora vamos a crear la API para poder usar el motor de búsqueda.</p>
<ol style="list-style-type: decimal">
<li><p>Vamos a la <a href="https://console.developers.google.com/">consola de desarrollador de Google.</a></p></li>
<li><p>Una vez dentro vamos a crear un nuevo proyecto, la primer ventana mostrará un aviso para crear un nuevo proyecto, hacemos clic en el botón de <strong>crear</strong>.</p></li>
</ol>
<p><img src="img/api1.JPG" /><br />
</p>
<ol start="3" style="list-style-type: decimal">
<li>En el siguiente formulario ponemos el nombre del proyecto, ID, la organización (puede ser cualquiera), ubicación (carpeta donde se guardara el proyecto). Cuando el formulario esté lleno pulsamos el botón de <strong>crear</strong>.</li>
</ol>
<blockquote>
<p>El nombre e ID del proyecto no se pueden cambiar una vez creado.</p>
</blockquote>
<p><img src="img/api2.JPG" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Una vez creado el proyecto activaremos la API, vamos a la <strong>biblioteca de APIs</strong>.</li>
</ol>
<p><img src="img/api3.JPG" /></p>
<ol start="5" style="list-style-type: decimal">
<li>En el buscador colocamos <em>custom search</em> y nos mostrara la API que necesitamos. Procedemos a <strong>Habilitar</strong> la API.</li>
</ol>
<p><img src="img/api4.jpg" /></p>
<ol start="6" style="list-style-type: decimal">
<li>Hasta el momento tenemos la API habilitada pero para tener acceso a ellas es necesario crear <em>credenciales</em>. Por lo tanto pulsamos el botón de <strong>Crear credenciales</strong>.</li>
</ol>
<p><img src="img/api5.JPG" /></p>
<ol start="7" style="list-style-type: decimal">
<li>Una vez dentro pulsamo <strong>clave de API</strong> esto nos brinda una manera sencilla de crear credenciales sin configuración extra.</li>
</ol>
<p><img src="img/api6.JPG" /></p>
<ol start="8" style="list-style-type: decimal">
<li>Colocamos el nombre de la API y sus restricciones, si quieres tener más seguridad en cómo se accesa a la API, configura las restricciones (No es necesario).</li>
</ol>
<p><img src="img/api7.JPG" /></p>
<p>Una vez generada la clave API nos aparecerá la siguiente ventana, copiamos la clave y la guardamos en algún lugar.</p>
<p><img src="img/api8.png" /></p>
<blockquote>
<p>Aquí se termina la configuración de la Custom Search API</p>
</blockquote>
<p>La documentación de API Google Custom Search se encuentra en <a href="https://developers.google.com/custom-search/" class="uri">https://developers.google.com/custom-search/</a>.</p>
</div>
<div id="configuracion-en-r" class="section level5">
<h5>Configuración en R</h5>
<p>En R creamos variables con la <em>clave API</em>, <em>ID del motor de búsqueda</em> y el valor de <em>N</em> en la fórmula <strong>NGD</strong>.</p>
<blockquote>
<p>Para obtener el numero de paginas indexadas por Google (<em>N</em>) se estimó por el numero de resultados del término de búsqueda <em>la</em>, que fue 25,270,000,000 resultados.</p>
</blockquote>
<pre class="r"><code>api_key &lt;- &quot;Mi_API_Key&quot;
id_engine &lt;- &quot;Mi_ID_Engine&quot;
M &lt;- 25270000000</code></pre>
<p>La función encargada de realizar las consultas y devolver el resultado es la siguiente:</p>
<pre class="r"><code>hits &lt;- function(word, aux.word=&quot;&quot;){
  # Comprobamos si paso el parámetro de palabra auxiliar
  if(aux.word==&quot;&quot;)
    query=paste(&quot;https://www.googleapis.com/customsearch/v1?key=&quot;, api_key , 
                &quot;&amp;cx=&quot;, id_engine, &quot;&amp;q=&quot;,word, sep=&quot;&quot;)
  else
    query=paste(&quot;https://www.googleapis.com/customsearch/v1?key=&quot;, api_key , 
                &quot;&amp;cx=&quot;, id_engine, &quot;&amp;q=&quot;,aux.word,&quot;+&quot;, word, sep=&quot;&quot;)
  
  # Se extraen los datos en formato JSON
  json_datos &lt;- content(GET(query))
  
  # Lista donde se encuentran los datos
  list_query &lt;- json_datos$queries$request
  
  # Se convierte el valor a numérico
  num_resul &lt;- as.numeric(list_query[[1]][2])
  return(num_resul)
}</code></pre>
</div>
</div>
</div>
<div id="matriz-ngd" class="section level3">
<h3>Matriz NGD</h3>
<p>Un limitante que se encuentra es la forma de obtener la cantidad de resultados por una consulta, para poder realizar de forma automática cada búsqueda es necesaria una API de Google pero su uso gratuito se limita a un total de 100 consultas al día. Para saber cuántas consultas se deben realizar para generar una matriz de <em>n</em> x <em>n</em> se desarrolló la siguiente ecuación:</p>
<p><span class="math display">\[ TotalConsultas = \frac{n^2 + n}{2} \]</span></p>
<p>La ecuación se escribe en R de la siguiente forma.</p>
<pre class="r"><code>n &lt;- length(total.top5)
num.query &lt;- (n^2 + n) / 2
num.query</code></pre>
<pre><code>## [1] 3655</code></pre>
<p>Se usaran los primero diez grupos esto nos lleva a una matriz de 10 x 10 con un total de consultas de 55.</p>
<pre class="r"><code># Extraemos los primeros diez grupos
vec.10.top5.words &lt;- total.top5[1:10]
vec.10.top5.words</code></pre>
<pre><code>##  [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot;</code></pre>
<blockquote>
<p>Motor de búsqueda: <strong>Google</strong></p>
</blockquote>
<p>Para realizar las consultas en el motor de búsqueda de Google debemos de haber realizado los pasos anteriores y haber configurado la API.</p>
<p>Vamos a realizar las consultas individuales para cada grupo. Se guardaran en un vector para su posterior uso para la construcción de la matriz NGD</p>
<pre class="r"><code># Vector donde se guardan los hits de las consultas
hits.vec10.top5 &lt;- 0
for (i in 1:10) {
  hits.vec10.top5[i] &lt;- hits(vec.10.top5.words[i])
}
hits.vec10.top5</code></pre>
<p>Para generar la matriz NGD creamos una <em>matrix</em> de ceros con dimensiones 10 por 10 y colocamos de nombre a las columnas y filas el vector con los 10 grupos.</p>
<pre class="r"><code># Creamos la matriz
mat.10.ngd &lt;- matrix(0, ncol=10, nrow=10)
# Se cambia el nombre a las filas y columnas
colnames(mat.10.ngd) &lt;- vec.10.top5.words
rownames(mat.10.ngd) &lt;- vec.10.top5.words
# Mostramos los primeros cinco elementos
mat.10.ngd[1:5,1:5]</code></pre>
<p>Ahora ya se pueden realizar las consultas cuando los dos términos están presentes. Se crean dos anidados que serán los encargados de recorrer la mitad de la matriz por ser simétrica. Para realizar la consulta <em>f(x, y)</em> se unen los dos términos que están en la fila y la columna con el carácter <strong>+</strong> y sacamos los hits de la búsqueda. Se guardan en la posición actual y su posición simétrica. Se crea un vector para guardar los hits cuando se hace la consulta. Este vector es recorrido por un contador.</p>
<pre class="r"><code># Vector para guardar los hits cuando ambos términos realizan la consulta
hits.mat10.ngd &lt;- 0
# Contador para recorrer el vector
conta &lt;- 1
for (i in 1:nrow(mat.10.ngd)) { 
  for (j in i:1) {
    if(i != j){ # Condición para no evaluar la diagonal principal de la matriz
      # Se pegan el termino de la columna con la matriz
      words.paste &lt;- paste(colnames(mat.10.ngd)[j], rownames(mat.10.ngd)[i], sep = &quot;+&quot;)
      # Se calculan los hits para la búsqueda con ambos términos
      hits.mat10.ngd[conta] &lt;- hits(words.paste)
      # Se guarda en la posición de la matriz y su posición simétrica
      mat.10.ngd[i,j] &lt;- mat.10.ngd[j,i] &lt;- NGD(hits.vec10.top5[i], hits.vec10.top5[j], hits.mat10.ngd[conta])
      # Aumentamos el contador para recorrer el vector de los hits
      conta &lt;- conta + 1
    }
  }
}</code></pre>
<p>Para visualizar los resultamos usamos una gráfica de correlación y el agrupamiento jerárquico.</p>
<pre class="r"><code>corrplot(mat.10.ngd, is.corr = F, method = &quot;circle&quot;, tl.cex = 0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre class="r"><code>plot(hclust(as.dist(mat.10.ngd)), cex = 0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-34-2.png" width="672" /></p>
<p>Ahora se realizaran las consulas con la palabra auxiliar “liniero”. Los pasos son exactamente los mismo sólo que cuando usamos la función <em>hits</em> debemos de agregar la palabra clave.</p>
<pre class="r"><code># Ejemplo de uso de la función
hits(word=&quot;abrazadera&quot;, aux.word = &quot;liniero&quot;)</code></pre>
<p>La matriz generada con este tipo de consulta queda de la siguiente manera.</p>
<pre class="r"><code>corrplot(mat.10.ngd.aux, is.corr = F, method = &quot;circle&quot;, tl.cex = 0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<pre class="r"><code>plot(hclust(as.dist(mat.10.ngd.aux)), horiz=T)</code></pre>
<pre><code>## Warning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :
## &quot;horiz&quot; is not a graphical parameter

## Warning in graphics:::plotHclust(n1, merge, height, order(x$order), hang, :
## &quot;horiz&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in axis(2, at = pretty(range(height)), ...): &quot;horiz&quot; is not a
## graphical parameter</code></pre>
<pre><code>## Warning in title(main = main, sub = sub, xlab = xlab, ylab = ylab, ...):
## &quot;horiz&quot; is not a graphical parameter</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-36-2.png" width="672" /></p>
<blockquote>
<p>Motor de búsqueda: <strong>Bing</strong></p>
</blockquote>
<p>Para realizar consultas en este motor de búsqueda no es necesaria una API. Se extrae el HTML de una consulta y navegando a través de los elementos se puede encontrar el número de resultados arrojados por la consulta. La función para realizar consultas en Bing queda de la siguiente manera.</p>
<pre class="r"><code>hits_bing  &lt;- function(word, aux.word = &quot;&quot;) {
  # Comprobamos si paso el parámetro de palabra auxiliar
  if(aux.word == &quot;&quot;){
    urlBing &lt;- paste(&quot;https://www.bing.com/search?q=&quot;, word, sep = &quot;&quot;)
  } else {
    urlBing &lt;- paste(&quot;https://www.bing.com/search?q=&quot;,aux.word, &quot;+&quot;, word, sep = &quot;&quot;)
  }
  # Se extraer el HTML de la página
  pagina &lt;-  read_html(urlBing)
  # Se busca el elemento HTML donde están los resultados
  hits_html &lt;- html_nodes(pagina, &quot;span.sb_count&quot;)
  hits_texto &lt;- html_text(hits_html)
  # Retorna el número de resultados
  return(as.numeric(gsub(&quot;,&quot;,&quot;&quot;,gsub(&quot; resultados&quot;, &quot;&quot;, hits_texto))))
}</code></pre>
<p>Se realizan los mismo pasos mencionados en el motor de búsqueda de Google solamente se sustituye la función de <strong>hits</strong> por <strong>hits_bing</strong></p>
<p>Los resultados en este motor de búsqueda sin palabra clave son los siguientes:</p>
<pre class="r"><code>corrplot(mat.10.ngd.bing, is.corr = F, method = &quot;circle&quot;, tl.cex = 0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<pre class="r"><code>plot(hclust(as.dist(mat.10.ngd.bing)))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-38-2.png" width="672" /></p>
<p>Los resultados en el motor de búsqueda Bing con palabra clave “liniero” son los siguientes</p>
<pre class="r"><code>corrplot(mat.10.ngd.bing.aux, is.corr = F, method = &quot;circle&quot;, tl.cex = 0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>plot(hclust(as.dist(mat.10.ngd.bing.aux)))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-39-2.png" width="672" /></p>
</div>
</div>
<div id="agrupacion-jerarquica-dentro-de-cluster" class="section level2">
<h2>Agrupación jerárquica dentro de Cluster</h2>
<p>Algunos grupos contiene más de dos documento, podemos usar, una vez más, la distancia NGD para agrupar jerárquicamente estos documentos.</p>
<p>Primero seleccionamos el número de cluster al que vamos a aplicar la agrupación jerarqioca, extraemos sus documentos en un vector y repetimos los pasos para la construcción de la matriz NGD.</p>
<pre class="r"><code># Seleccionamos el número de cluster
num.cluster &lt;- 3
# Extraemos los documentos
df.cluster.contenido &lt;- df.doc.cluster %&gt;%
  filter(cluster==num.cluster)
# Convertimos en vector
df.cluster.contenido &lt;- as.vector(df.cluster.contenido$id.doc)</code></pre>
<p>Aplicamos la función para extraer las cinco palabras más usadas dentro del <em>documento</em>.</p>
<pre class="r"><code># Vector para guardar las top cinco palabras por documento
docs.in.cluster &lt;- 0
# Ciclo para extraer las cinco palabras más usadas
for (i in 1:length(df.cluster.contenido)) {
  docs.in.cluster[i] &lt;- top.5.words(df.cluster.contenido[i])
}
docs.in.cluster</code></pre>
<pre><code>## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot;</code></pre>
<p>Procedemos a realizar los hits de manera individual para cada documento.</p>
<pre class="r"><code># Vector para guardar los hits
hits.total.docs.in.cluster &lt;- 0
for (i in 1:length(df.cluster.contenido)) {
  hits.total.docs.in.cluster[i] &lt;- hits(docs.in.cluster[i])
}</code></pre>
<p>Creamos la matriz NGD para después ejecutar los hits</p>
<pre class="r"><code># Se crea la matriz
matriz.ngd.cluster.3 &lt;- matrix(0, ncol=length(hits.total.docs.in.cluster), nrow=length(hits.total.docs.in.cluster))
# Colocamos nombre a las filas y columnas
colnames(matriz.ngd.cluster.3) &lt;- docs.in.cluster
rownames(matriz.ngd.cluster.3) &lt;- docs.in.cluster
View(matriz.ngd.cluster.3)

# Vector donde se guardan los hits
hits.docs.paste.in.cluster &lt;- 0
conta &lt;- 1
for (i in 1:nrow(matriz.ngd.cluster.3)) {
  for (j in i:1) {
    if(i != j){
      # Fusión de las fias y columnas
      words.paste &lt;- paste(colnames(matriz.ngd.cluster.3)[j], rownames(matriz.ngd.cluster.3)[i], sep = &quot;+&quot;)
      # Vector para guardar los hits
      hits.docs.paste.in.cluster[conta] &lt;- hits.with.aux(word = words.paste, aux.word = &quot;liniero&quot;)
      # Aplicación de la NGD
      matriz.ngd.cluster.3[i,j] &lt;- matriz.ngd.cluster.3[j,i] &lt;- NGD(copia.hits.total.docs.in.cluster.5[i], copia.hits.total.docs.in.cluster.5[j], hits.docs.paste.in.cluster[conta])
      # Contador para vectores con los hits
      conta &lt;- conta + 1
    }
  }
}</code></pre>
<p>Graficamos para visualizar los resultados.</p>
<pre class="r"><code># Correlación
corrplot.mixed(matriz.ngd.cluster.3, is.corr = F, upper = &quot;circle&quot;, lower=&quot;number&quot;, lower.col = &quot;black&quot;, tl.pos = &quot;lt&quot;, tl.cex=0.65)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<pre class="r"><code># Clustering jerarquico
plot(hclust(as.dist(matriz.ngd.cluster.3)))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-44-2.png" width="672" /></p>
<p>Para comparar la similitud entre las clusterings obtenidos por las cuatro configuraciones antes enumeradas, utilizamos el índice de Jaccard. Para ello se realizó clusterings a las matrices (Google y Bing, con y sin palabra) desde k=2 a k=10, con esto buscamos determinar el k donde las agrupaciones tienen mayor concordancia.</p>
<p>Necesitamos una función que compare el índice de Jaccard entre dos vectores. La siguiente función recibe dos vectores y su tamaño. Primero se crea una matriz de ceros de dimensiones según el tamaño en el parámetro. Dos ciclos anidados evalúa el índice de Jaccard de cada elemento en los vectores. Se necesita la máxima similitud de cada comparación, por lo tanto, se recorre parte de la matriz en busca de los valores máximos para formar un vector. Una vez calculador se retorna el promedio de las máximas similitudes.</p>
<pre class="r"><code>jaccard.mean.vector &lt;- function(x, y, size){
  # Matriz temporal de ceros
  matriz.temp &lt;- matrix(0, ncol = size, nrow = size)
  for (i in 1:size) {
    for (j in 1:size) {
      # Cálculo del índice de Jaccard
      matriz.temp[i,j] &lt;- jaccard(x==i, y==j)
    }
  }
  # Vector para guardar las máximas similitudes
  max.value &lt;- 0
  for (i in 1:size) {
    max.value[i] &lt;- max(matriz.temp[i,])  
  }
  # Retornamos el promedio del vector de máximas similitudes
  return(mean(max.value))
}</code></pre>
<p>También se necesita una función que nos genere la similitud con el índice de Jaccard entre cada matriz.</p>
<p>La función recibe como parámetro una lista de las agrupaciones para cada matriz que van a ser comparadas. Se crea una matriz de ceros de dimensiones al total de vectores en la lista. Dos ciclos anidados recorren la matriz y con la función <em>jaccard.mean.vector</em> compara los vectores entre sí. Después buscamos la máxima similitud entre las diferentes matrices, así mismo la similitud entre todas las matrices NGD.</p>
<pre class="r"><code>jaccard.mean.with.list &lt;- function(vector.todos, k) {
  temp.return &lt;- list()
  mat.temp &lt;- matrix(0, ncol = length(vector.todos), nrow = length(vector.todos))
  for (i in 1:length(vector.todos)) {
    for (j in 1:length(vector.todos)) {
      mat.temp[i,j] &lt;- jaccard.mean.vector(vector.todos[[i]], vector.todos[[j]], k)
    }
  }
  vec.test &lt;- 0
  for (i in 1:4) {
    vec.test[i] &lt;- (sum(mat.temp[,i]) - 1) / 3
  }
  temp.return$mean.max &lt;- max(vec.test)
  temp.return$goo_goo.aux &lt;- mat.temp[1,2]
  temp.return$goo_bing &lt;- mat.temp[1,3]
  temp.return$goo_bing.aux &lt;- mat.temp[1,4]
  temp.return$goo.aux_bing &lt;- mat.temp[2,3]
  temp.return$goo.aux_bing.aux &lt;- mat.temp[2,4]
  temp.return$bing_bing.aux &lt;- mat.temp[3,4]
  temp.return$matriz &lt;- mat.temp
  return(temp.return)
}</code></pre>
<p>Ahora se utilizaran las funciones anteriormente creadas, necesitamos un vector para cada comparación entre matrices. Creamos un ciclo con el número de cluster que queremos hacer las pruebas, para cada matriz NGD diferente aplicamos la función <em>cutree</em> para crear grupos de acuerdo al agrupamiento jerárquico, después, agregamos a cada vector de comparación entre matrices.</p>
<pre class="r"><code># Vectores para guardar la similitud entre matrices
goo_goo.aux.vec &lt;- 0
goo_bing.vec &lt;- 0
goo_bing.aux.vec &lt;- 0
goo.aux_bing.vec &lt;- 0
goo.aux_bing.aux.vec &lt;- 0
bing_bing.aux.vec &lt;- 0
jaccard.means.vec &lt;- 0

for (i in 1:10) {
  # Aplicamos agrupacion de acuerdo al número de grupos que necesitamos
  goo &lt;- cutree(hclust(as.dist(mat.10.ngd)), k = i)
  goo_aux &lt;- cutree(hclust(as.dist(mat.10.ngd.aux)), k = i)
  bing &lt;- cutree(hclust(as.dist(mat.10.ngd.bing)), k = i)
  bing_aux &lt;- cutree(hclust(as.dist(mat.10.ngd.bing.aux)), k = i)
  means_k &lt;- jaccard.mean.with.list(list(goo, goo_aux, bing, bing_aux), k = i)
  # Asignamos a los datos a los vectores
  goo_goo.aux.vec[i] &lt;- means_k$goo_goo.aux
  goo_bing.vec[i] &lt;- means_k$goo_bing
  goo_bing.aux.vec[i] &lt;- means_k$goo_bing.aux
  goo.aux_bing.vec[i] &lt;- means_k$goo.aux_bing
  goo.aux_bing.aux.vec[i] &lt;- means_k$goo.aux_bing.aux
  bing_bing.aux.vec[i] &lt;- means_k$bing_bing.aux
  jaccard.means.vec[i] &lt;- means_k$mean.max
}</code></pre>
<p>Después, creamos un <em>data frame</em> con el número de cluster y la similitud entre todas las matrices para después graficarlas.</p>
<pre class="r"><code>df.data.uni &lt;- tibble(
  cluster = 1:10,
  Promedio = jaccard.means.vec,
  Google_GoogleAux = goo_goo.aux.vec,
  Google_Bing = goo_bing.vec,
  Google_BingAux = goo_bing.aux.vec,
  GoogleAux_Bing = goo.aux_bing.vec,
  GoogleAux_BingAux = goo.aux_bing.aux.vec,
  Bing_BingAux = bing_bing.aux.vec
)

## Graficar
df.data.uni %&gt;%
  gather(income, frecuency, -cluster) %&gt;%
  ggplot(aes(x=cluster, y=frecuency, color=income, group=income)) +
  geom_line() +
  geom_point() +
  labs(color=&quot;Comparation&quot;, y=&quot;Jaccard Similarity&quot;, x= &quot;Cluster&quot;) +
  scale_x_discrete(limits=1:10) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>En la gráfica se puede observar cual es el valor optimo de cluster dentro de las matrices</p>
</div>
<div id="resultados" class="section level2">
<h2>Resultados</h2>
<p>Adicionalmente, se compararon los modelos obtenidos respecto a la agrupación de un experto. De igual forma, se compararon con el índice de Jaccard todas las matrices generadas con la NGD.</p>
<p>Se debe de crear una agrupación manual de un experto para posteriormente compararlo con todas las matrices. Primero elegimos el número de clusters que tendrá el grupo.</p>
<pre class="r"><code># Número de agrupaciones
i &lt;- 3
# Vector con la agrupación generada por el experto
expert.mat &lt;- cutree(hclust(as.dist(mat.10.ngd)), k = i)
expert.mat[1] &lt;- 1
expert.mat[2] &lt;- 2
expert.mat[3] &lt;- 2
expert.mat[4] &lt;- 2
expert.mat[5] &lt;- 1
expert.mat[6] &lt;- 1
expert.mat[7] &lt;- 1
expert.mat[8] &lt;- 2
expert.mat[9] &lt;- 3
expert.mat[10] &lt;- 3</code></pre>
<p>Creamos la agrupación para cada matriz diferente</p>
<pre class="r"><code>goo &lt;- cutree(hclust(as.dist(mat.10.ngd)), k = i)
goo_aux &lt;- cutree(hclust(as.dist(mat.10.ngd.aux)), k = i)
bing &lt;- cutree(hclust(as.dist(mat.10.ngd.bing)), k = i)
bing_aux &lt;- cutree(hclust(as.dist(mat.10.ngd.bing.aux)), k = i)</code></pre>
<p>Creamos un vector donde se guardaran las comparaciones y lo tranformamos a un <em>dataframe</em></p>
<pre class="r"><code>resul &lt;- 1:4
resul[1] &lt;- jaccard.mean.vector(expert.mat, goo, i)
resul[2] &lt;- jaccard.mean.vector(expert.mat, goo_aux, i)
resul[3] &lt;- jaccard.mean.vector(expert.mat, bing, i)
resul[4] &lt;- jaccard.mean.vector(expert.mat, bing_aux, i)

# Convertimos a un dataframe
resul &lt;- as.data.frame(resul)</code></pre>
<p>Agregamos una columna al <em>dataframe</em> con el nombre del motor de busqueda para posteriormente graficar.</p>
<pre class="r"><code># Colocamos el tipo de motor de cada relación
resul$engNum &lt;- c(&quot;Google&quot;, &quot;Google&quot;, &quot;Bing&quot;,&quot;Bing&quot;)
resul$engine &lt;- c(&quot;Google&quot;, &quot;Google.Auxiliar&quot;, &quot;Bing&quot;, &quot;Bing.Auxiliar&quot;)

# Use position=position_dodge()
ggplot(data=resul, aes(x=engine, y=resul, fill=engNum)) +
  geom_bar(stat=&quot;identity&quot;) +
  ylim(0, 1) +
  coord_flip() +
  labs(y= &quot;Similaridad de Jaccard&quot;, fill=&quot;Motor de busqueda&quot;, x=&quot;&quot;) + 
  scale_x_discrete(limits=c(&quot;Google&quot;, &quot;Bing.Auxiliar&quot;, &quot;Bing&quot;, &quot;Google.Auxiliar&quot;))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusión</h1>
<p>En el proyecto, se presentó un modelo para generar una ontología que permita relacionar las herramientas, equipamiento y materiales requeridos para las maniobras de mantenimiento en la infraestructura de media tensión utilizando algoritmos de agrupamiento no supervisado a partir de una medida de similitud semántica, la Distancia Normalizada de Google. Hay un conjunto de posibles mejoras para el trabajo realizado: a) se puede omitir la etapa de agrupación de los equipos de tal forma que directamente se aplique la NGD a los equipos, b) en la etapa de preprocesamiento se pueden eliminar los documentos repetidos sin necesidad de aplicar el índice de Jaccard, ahorrando costo computacional y c) configurar el motor de Google para mostrar resultados más relacionados al área de interés.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Instituto de Electricidad y Energías Limpias , <a href="mailto:guillermo.santamaria@ineel.mx" class="email">guillermo.santamaria@ineel.mx</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Universidad de Colima, <a href="mailto:hdiaz6@ucol.mx" class="email">hdiaz6@ucol.mx</a><a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
